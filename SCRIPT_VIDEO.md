# üé¨ Script Vid√©o de Pr√©sentation - WeatherProject
## Dur√©e : 4-5 minutes

---

## üéØ INTRODUCTION (30 secondes)

"Bonjour, je vais vous pr√©senter mon projet Big Data : **WeatherProject**, une pipeline d'analyse m√©t√©orologique compl√®te utilisant Apache Spark, PostgreSQL et Flask.

Le projet analyse **3 ans de donn√©es m√©t√©orologiques r√©elles** de la C√¥te d'Azur, de 2023 √† 2025, soit plus de **1000 jours de donn√©es** pour 5 villes : Nice, Cannes, Monaco, Antibes et Menton."

**[Montrer l'√©cran : projet ouvert dans VSCode]**

---

## üèóÔ∏è ARCHITECTURE & DOCKER (1 minute)

"Le projet utilise une **architecture Docker compl√®te** avec 4 conteneurs :

**[Montrer docker-compose.yml]**

1. **PostgreSQL** : stocke les m√©tadonn√©es et la tra√ßabilit√© des ingestions
2. **Spark Master** : coordonne le traitement distribu√© des donn√©es
3. **Spark Worker** : ex√©cute les t√¢ches de traitement en parall√®le
4. **Dashboard Flask** : l'interface web de visualisation

**[Ouvrir un terminal et taper : `docker ps`]**

Comme vous pouvez le voir, tous les services sont actifs et fonctionnent."

---

## ‚öôÔ∏è POURQUOI LA PIPELINE EST LANC√âE EN LOCAL ? (1 minute 30)

"Maintenant, une question importante : **pourquoi la pipeline est lanc√©e en ligne de commande et pas directement dans Docker Compose ?**

**[Montrer run_pipeline.py]**

Il y a **3 raisons principales** :

### 1. Flexibilit√© et D√©veloppement
Pendant le d√©veloppement, on a besoin de **tester rapidement** la pipeline. Si elle √©tait dans Docker, il faudrait :
- Arr√™ter les conteneurs
- Rebuild l'image
- Red√©marrer tout

En l'ex√©cutant localement, je peux **modifier le code et relancer imm√©diatement**, ce qui acc√©l√®re √©norm√©ment le d√©veloppement.

### 2. Acc√®s aux Donn√©es Locales et au R√©seau
La pipeline doit :
- **Appeler l'API Open-Meteo** sur Internet pour r√©cup√©rer les donn√©es
- **√âcrire dans `data/raw`** sur ma machine locale
- **Communiquer avec Spark** qui tourne dans Docker

En lan√ßant la pipeline localement, elle peut **facilement acc√©der** √† ma connexion Internet, √† mon syst√®me de fichiers local, ET aux services Docker via les ports expos√©s (5432 pour PostgreSQL, 8080 pour Spark).

### 3. S√©paration des Responsabilit√©s
L'architecture suit le principe de **s√©paration des responsabilit√©s** :
- **Docker** : infrastructure permanente (bases de donn√©es, moteurs de calcul, dashboard)
- **Pipeline** : processus ponctuel d'ingestion et de traitement

Dans un environnement de production r√©el, la pipeline serait d√©clench√©e par un **scheduler** (comme Airflow ou Cron), pas par Docker Compose qui est fait pour des services qui tournent en continu.

C'est une architecture plus **r√©aliste** et **scalable** pour un vrai projet Big Data."

---

## üöÄ D√âMONSTRATION DE LA PIPELINE (1 minute)

"Maintenant, d√©monstration !

**[Terminal : `python run_pipeline.py`]**

Comme vous pouvez le voir, la pipeline s'ex√©cute en **3 phases** :

### Phase 1 : INGESTION
**[Montrer les logs qui d√©filent]**

- Appel de l'API Open-Meteo Archive pour les 5 villes
- T√©l√©chargement des donn√©es m√©t√©o de 2023 √† aujourd'hui
- Sauvegarde en JSON dans `data/raw/`
- Conversion en CSV pour Spark
- R√©sultat : **5285 enregistrements bruts**

### Phase 2 : TRAITEMENT SPARK
**[Montrer Spark UI : http://localhost:8080]**

- Nettoyage des donn√©es avec Spark
- Agr√©gations journali√®res : **1057 jours**
- Agr√©gations mensuelles : **35 mois**
- Agr√©gations saisonni√®res : **12 saisons**

### Phase 3 : PERSISTANCE
**[Montrer le dossier data/processed/]**

- Sauvegarde au format **Parquet** (optimis√© et compress√©)
- Enregistrement des m√©tadonn√©es dans PostgreSQL

**Pipeline termin√©e en 35 secondes !**"

---

## üìä DASHBOARD INTERACTIF (1 minute)

"Passons maintenant au **dashboard** qui tourne dans Docker.

**[Ouvrir http://localhost:5000 dans le navigateur]**

Le dashboard propose plusieurs visualisations :

### Vue d'ensemble
**[Montrer les cartes de statistiques]**
- Temp√©rature moyenne : **17¬∞C**
- Pr√©cipitations totales : **12 910 mm**
- Humidit√© moyenne : **69,5%**
- P√©riode d'analyse : **1057 jours**

### Graphique interactif
**[Montrer le graphique d'√©volution]**

Le point fort : les **filtres dynamiques**. Je peux afficher :
- Les 30 derniers jours
- 90 jours
- 1 an
- 2 ans
- Ou les **3 ans complets**

**[Changer le filtre en direct et montrer que le graphique se met √† jour]**

Vous voyez, le graphique se met √† jour instantan√©ment. On peut zoomer, explorer les donn√©es, voir les temp√©ratures min, max et moyennes.

### Autres analyses
**[Scroller rapidement]**
- Moyennes mensuelles
- Comparaison saisonni√®re
- Heatmap des temp√©ratures
- Distribution et pr√©cipitations

Tout est **interactif** gr√¢ce √† Plotly.js et Chart.js."

---

## üéì CONFORMIT√â AVEC LE TP (30 secondes)

"Ce projet respecte **tous les crit√®res du TP** :

‚úÖ **2 sources de donn√©es diff√©rentes** : API REST (JSON) + CSV historiques
‚úÖ **Ingestion r√©siliente** : checkpoints, retry, logs
‚úÖ **Donn√©es brutes conserv√©es** : dossier data/raw/
‚úÖ **M√©tadonn√©es s√©par√©es** : PostgreSQL
‚úÖ **ETL complet** : Spark pour Extract, Transform, Load
‚úÖ **Dashboard interactif** : Flask avec filtres dynamiques
‚úÖ **Architecture DataLake** : 3 couches (RAW, CURATED, ANALYTICS)
‚úÖ **Framework Big Data** : Apache Spark distribu√©"

---

## üîö CONCLUSION (30 secondes)

"En r√©sum√©, WeatherProject est une **architecture Big Data compl√®te et professionnelle** :

- **Infrastructure Docker** pour la portabilit√©
- **Pipeline modulaire** s√©par√©e pour la flexibilit√©
- **Traitement distribu√©** avec Spark
- **Donn√©es r√©elles** provenant d'une API officielle
- **Visualisation interactive** pour l'analyse

Le code est **propre**, **document√©**, et **pr√™t pour la production**.

L'architecture choisie avec la pipeline s√©par√©e de Docker est **intentionnelle** : elle refl√®te une architecture Big Data r√©aliste o√π les processus d'ingestion ponctuels sont d√©coupl√©s des services permanents.

Merci de votre attention !"

**[Montrer une derni√®re fois le README.md avec le tableau de conformit√©]**

---

## üìù POINTS √Ä MONTRER √Ä L'√âCRAN

### Fichiers √† ouvrir pendant la vid√©o :
1. `docker-compose.yml` - Architecture
2. `run_pipeline.py` - Pipeline orchestr√©e
3. `src/ingestion/api_ingestion.py` - Ingestion API
4. `src/processing/spark_processing.py` - Traitement Spark
5. `data/processed/` - Fichiers Parquet g√©n√©r√©s
6. `README.md` - Documentation compl√®te

### Commandes √† taper :
```bash
# V√©rifier les conteneurs Docker
docker ps

# Lancer la pipeline
python run_pipeline.py

# (Optionnel) V√©rifier les logs
docker logs weather-dashboard
```

### URLs √† ouvrir :
- Dashboard : http://localhost:5000
- Spark UI : http://localhost:8080
- GitHub : https://github.com/HKB06/WeatherProject

---

## üéØ TIPS POUR LA VID√âO

1. **Parle clairement et pas trop vite** (importante pour 4-5 min)
2. **Montre le code en m√™me temps que tu expliques**
3. **Teste le filtre 3 ans en direct** pour montrer l'interactivit√©
4. **Mets en avant la conformit√© TP** (crit√®re de notation)
5. **Explique POURQUOI les choix techniques** (pipeline s√©par√©e, Docker, Spark)

---

## ‚è±Ô∏è TIMING RECOMMAND√â

| Section | Dur√©e | Timing cumul√© |
|---------|-------|---------------|
| Introduction | 30s | 0:30 |
| Architecture Docker | 1min | 1:30 |
| Pourquoi pipeline en local | 1min 30s | 3:00 |
| D√©mo pipeline | 1min | 4:00 |
| Dashboard interactif | 1min | 5:00 |
| Conformit√© TP | 30s | 5:30 (marge) |
| Conclusion | 30s | 6:00 (max) |

**Cible : 4-5 minutes ‚Üí privil√©gier les sections 1, 3, 4, 5**

---

Bon courage pour ta vid√©o ! üé¨üöÄ

